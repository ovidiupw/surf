\newcommand{\xmlDescription}{Extensible Markup Language - https://www.w3.org/XML/}
\newcommand{\jsonDescription}{JavaScript Object Notation - http://www.json.org/}
\newcommand{\crawlDescription}{Web crawler - https://www.techopedia.com/definition/10008/web-crawler}
\newcommand{\restDescription}{REST - http://www.ics.uci.edu/~fielding/pubs/dissertation/rest\_arch\_style.htm}
\newcommand{\awsDescription}{Amazon Web Services - https://aws.amazon.com}

Un serviciu web reprezinta o componenta functionala ce indeplineste anumite sarcini. Comunicarea cu un serviciu web se realizeaza independent de platforma, limbajul de programare sau sistemul de operare pe care este dezvoltat. Schimbul de informatii se realizeaza prin mesaje text ce respecta un format standardizat precum xml\footnote{\xmlDescription} sau json\footnote{\jsonDescription}. 
\\
\\
Aplicatia "Surf" reprezinta un serviciu web specializat in web crawling\footnote{\crawlDescription}, dezvoltat folosind tehnologii cloud din cadrul Amazon Web Services. Se urmareste crearea unui serviciu web cu disponibilitate permanenta, scalabil si de inalta putere computationala care sa orchestreze colectarea distribuita de informatii din aria definita de utilizator.
\\
\\
Comunicarea cu aplicatia "Surf" se realizeaza prin intermediul unui API RESTful\footnote{\restDescription} construit pe platforma AWS\footnote{\awsDescription} API Gatway. Autentificarea utilizatorilor se va realiza printr-un serviciu OpenID Connect (e.g. Google, Facebook etc.). Autorizarea va avea ca principala componenta AWS IAM. Utilizatorilor le vor fi repartizate, in functie de privilegiile asociate cu cheia de autentificare, o serie de roluri (i.e. drepturi de access asupra resurselor din cadrul serviciului "Surf"). Executia codului propriu-zis, gazduit de functii AWS Lambda, va interactiona cu serviciul pentru baze de date no-sql AWS DynamoDB pentru a permite accesul la informatii cheie pentru functionalitatea aplicatiei (metadate crawling, date acces utilizatori etc.). Mediul de procesare distribuita va fi sustinut de AWS Simple Workflow Service si configurat dupa preferintele utilizatorului. Datele extrase din procesul de web-crawling vor fi salvate in mediul persistent de stocare AWS S3. Evenimentele legate de parcurgerea siturilor vor fi expuse, ca metadate, intr-o coada AWS SQS si vor fi accesibile utilizatorilor prin procesul de long-polling asupra acestei cozi.
