Datorita ritmului alert in care se creaza sau schimba informatiile apartinand world wide web-ului, exista o necesitate tot mai mare de a putea prelua si analiza datele intr-un mod automat, rapid si eficient. Crawlerii web sunt o componenta deosebit de importanta, in vederea extragerii si indexarii exhaustive a informatiilor, pentru motoarele de cautare. Cu toate acestea, avantajele aduse de catre crawleri pot fi folosite si pentru a extrage resurse relevante dintr-un anumit context, fara a fi necesara o parcurgere a tuturor resurselor web accesibile. Odata cu aparitia si dezvoltarea serviciilor web, infrastructura puternica si costurile reduse oferite de catre furnizorii cloud ofera modalitati flexibile, intuitive si extensibile de a sustine crawleri specializati. 
\\

Crawler-ul web "Surf" propune, in acest sens, o modalitate simpla pentru ca un utilizator interesat de resurse dintr-o anumita arie sa poata sa le preia automat si sa le analizeze continutul, fara a fi necesar sa depinda de furnizori terti de servicii web de crawling si cu posibilitatea de ajustare minutioasa a costurilor operationale. Flexibilitatea legata atat de costuri, cat si de design-ul arhitectural al aplicatiei "Surf", permite dezvoltatorilor interesati sa adauge functionalitati suplimentare precum elemente de tip map/reduce, analiza semantica a continutului paginilor web si tehnici euristice pentru selectarea frontierei de URL-uri din cadrul procesului de parcurgere a paginilor web. De asemenea, flexibilitatea serviciilor cloud garanteaza atingerea unui nivel de activitate de aproape 100\%, acest lucru oferind siguranta si incredere in utilizare.