În timpul execuției, crawler-ul generează evenimente ce sunt adaugate la istoricul execuției curente. Aceste evenimente sunt utile, în primul rând, în cazul în care execuția instanței curente a crawler-ului eșuează. Sarcinile de crawling web pot dura o perioadă considerabilă și nu este dezirabilă refacerea întregului proces de parcurgere a siturilor, atât timp cât există rezultate parțiale disponibile; execuția se poate relua pornind de la ultimul eveniment valid înregistrat în istoric.  În al doilea rand, istoricul este util pentru utilizator, deoarece îl poate avertiza în legătură cu starea execuției curente a web crawler-ului.
\\
\\
Datele rezultate în urma procesului de crawling al paginilor web sunt salvate în serviciul persistent de stocare S3, din cadrul Amazon Web Services. Deoarece aceste date pot deveni volumnioase (în funcție de politica de selecție configurată), aplicația "Surf" salvează metadate asociate acestor rezultate într-o tabela DynamoDB. Pe baza acestor informații (metadate), utilizatorul are opțiunea de a accesa rezultatele complete corespunzatoare rulării crawler-ului web, aflate în S3.