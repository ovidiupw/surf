Este necesar un client HTTP care trimite o cerere HTTP si primeste un raspuns. In aceasta etapa, nu trebuie trecut cu vederea "The Robots Exclusion Standard", cunoscul si drept "Robots Exclusion Standard" sau robots.txt \cite{RobotsStandard}. Protocolul ofera administratorilor de servere web posibilitatea de a-si comunica politicile de acces si de a mentiona paginile care nu sunt destinate crawler-ilor.
\\