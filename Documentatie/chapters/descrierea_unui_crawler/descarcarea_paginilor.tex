Este necesar un client HTTP care trimite o cerere HTTP și primește un raspuns. În această etapă, nu trebuie trecut cu vederea "The Robots Exclusion Standard", cunoscut și drept "Robots Exclusion Standard" sau robots.txt \cite{RobotsStandard}. Protocolul oferă administratorilor de servere web posibilitatea de a-și comunica politicile de acces și de a menționa paginile care nu sunt destinate crawler-ilor.
\\